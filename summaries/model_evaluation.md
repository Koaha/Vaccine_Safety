
# Model Evaluation Report

**AUC Score:** 0.7500  
**F1 Score:** 0.4000  

## Classification Report
```
              precision    recall  f1-score   support

           0       0.79      0.75      0.77        20
           1       0.38      0.43      0.40         7

    accuracy                           0.67        27
   macro avg       0.58      0.59      0.58        27
weighted avg       0.68      0.67      0.67        27

```

## Confusion Matrix
```
[[15  5]
 [ 4  3]]
```
